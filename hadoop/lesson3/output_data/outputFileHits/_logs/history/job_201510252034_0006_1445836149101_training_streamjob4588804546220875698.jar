Meta VERSION="1" .
Job JOBID="job_201510252034_0006" JOBNAME="streamjob4588804546220875698\.jar" USER="training" SUBMIT_TIME="1445836149101" JOBCONF="hdfs://0\.0\.0\.0:8020/var/lib/hadoop-hdfs/cache/mapred/mapred/staging/training/\.staging/job_201510252034_0006/job\.xml" VIEW_JOB="*" MODIFY_JOB="*" JOB_QUEUE="default" .
Job JOBID="job_201510252034_0006" JOB_PRIORITY="NORMAL" .
Job JOBID="job_201510252034_0006" LAUNCH_TIME="1445836149207" TOTAL_MAPS="12" TOTAL_REDUCES="1" JOB_STATUS="PREP" .
Task TASKID="task_201510252034_0006_m_000013" TASK_TYPE="SETUP" START_TIME="1445836149491" SPLITS="" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201510252034_0006_m_000013" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000013_0" START_TIME="1445836149590" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="SETUP" TASKID="task_201510252034_0006_m_000013" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000013_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836150624" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="setup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188118)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(40)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(42930176)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386060288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000013" TASK_TYPE="SETUP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836150720" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188118)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(0)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(1)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(40)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(42930176)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386060288)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201510252034_0006" JOB_STATUS="RUNNING" .
Task TASKID="task_201510252034_0006_m_000000" TASK_TYPE="MAP" START_TIME="1445836150722" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201510252034_0006_m_000001" TASK_TYPE="MAP" START_TIME="1445836150722" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000000" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000000_0" START_TIME="1445836150725" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000000" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000000_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836161127" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1369/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26124981)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52438099)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113069)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600016)][(MAP_OUTPUT_RECORDS)(Map output records)(600016)][(MAP_OUTPUT_BYTES)(Map output bytes)(24924414)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1200032)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3810)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195346432)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108974)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000000" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836161250" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26124981)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52438099)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113069)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600016)][(MAP_OUTPUT_RECORDS)(Map output records)(600016)][(MAP_OUTPUT_BYTES)(Map output bytes)(24924414)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1200032)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3810)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195346432)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108974)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000001" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000001_0" START_TIME="1445836150726" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000001" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000001_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836161175" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1198/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(25961411)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52110959)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600754)][(MAP_OUTPUT_RECORDS)(Map output records)(600753)][(MAP_OUTPUT_BYTES)(Map output bytes)(24759637)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1201506)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3810)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195383296)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108782)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000001" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836161252" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(25961411)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52110959)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(600754)][(MAP_OUTPUT_RECORDS)(Map output records)(600753)][(MAP_OUTPUT_BYTES)(Map output bytes)(24759637)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1201506)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3810)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195383296)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108782)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000002" TASK_TYPE="MAP" START_TIME="1445836161253" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201510252034_0006_m_000003" TASK_TYPE="MAP" START_TIME="1445836161253" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201510252034_0006_r_000000" TASK_TYPE="REDUCE" START_TIME="1445836161253" SPLITS="" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000002" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000002_0" START_TIME="1445836161255" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000002" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000002_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836172984" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1181/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26226314)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52640765)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596105)][(MAP_OUTPUT_RECORDS)(Map output records)(596095)][(MAP_OUTPUT_BYTES)(Map output bytes)(25033870)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1192190)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3700)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195096576)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000002" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836173022" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26226314)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52640765)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596105)][(MAP_OUTPUT_RECORDS)(Map output records)(596095)][(MAP_OUTPUT_BYTES)(Map output bytes)(25033870)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1192190)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3700)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195096576)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000003" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000003_0" START_TIME="1445836161256" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000003" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000003_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836172971" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1181/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26917839)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(54023815)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(586103)][(MAP_OUTPUT_RECORDS)(Map output records)(586102)][(MAP_OUTPUT_BYTES)(Map output bytes)(25744641)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1172204)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3650)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195452928)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000003" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836173022" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26917839)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(54023815)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(586103)][(MAP_OUTPUT_RECORDS)(Map output records)(586102)][(MAP_OUTPUT_BYTES)(Map output bytes)(25744641)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1172204)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3650)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195452928)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108872)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000004" TASK_TYPE="MAP" START_TIME="1445836173025" SPLITS="/default-rack/localhost\.localdomain" .
Task TASKID="task_201510252034_0006_m_000005" TASK_TYPE="MAP" START_TIME="1445836173025" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000004" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000004_0" START_TIME="1445836173026" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000004" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000004_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836185358" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1127/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26653174)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(53494485)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(590850)][(MAP_OUTPUT_RECORDS)(Map output records)(590840)][(MAP_OUTPUT_BYTES)(Map output bytes)(25470166)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1181680)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3740)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195051520)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108878)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000004" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836185366" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26653174)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(53494485)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(590850)][(MAP_OUTPUT_RECORDS)(Map output records)(590840)][(MAP_OUTPUT_BYTES)(Map output bytes)(25470166)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1181680)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3740)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195051520)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108878)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000006" TASK_TYPE="MAP" START_TIME="1445836185367" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000005" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000005_0" START_TIME="1445836173026" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000005" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000005_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836185497" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1108/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26229789)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52647715)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596948)][(MAP_OUTPUT_RECORDS)(Map output records)(596934)][(MAP_OUTPUT_BYTES)(Map output bytes)(25035035)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1193868)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3720)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195047424)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108834)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000005" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836185675" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26229789)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(52647715)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(596948)][(MAP_OUTPUT_RECORDS)(Map output records)(596934)][(MAP_OUTPUT_BYTES)(Map output bytes)(25035035)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1193868)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(3720)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195047424)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108834)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000007" TASK_TYPE="MAP" START_TIME="1445836185676" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000007" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000007_0" START_TIME="1445836185690" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000007" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000007_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836192493" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="hdfs://0\.0\.0\.0:8020/user/training/myinput/purchases\.txt:0+67108864" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188155)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113068)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1314296)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(155320320)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108867)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000007" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836192789" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188155)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113068)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1314296)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(155320320)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108867)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000008" TASK_TYPE="MAP" START_TIME="1445836192791" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000006" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000006_0" START_TIME="1445836185367" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000006" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000006_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836195300" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1112/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26450245)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(53088627)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(593809)][(MAP_OUTPUT_RECORDS)(Map output records)(593790)][(MAP_OUTPUT_BYTES)(Map output bytes)(25259898)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1187580)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(4040)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195325952)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108950)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000006" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836195579" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(26450245)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(53088627)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113070)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(593809)][(MAP_OUTPUT_RECORDS)(Map output records)(593790)][(MAP_OUTPUT_BYTES)(Map output bytes)(25259898)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(1187580)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(4040)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(195325952)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108950)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000009" TASK_TYPE="MAP" START_TIME="1445836195580" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000008" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000008_0" START_TIME="1445836192794" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000008" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000008_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836199895" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="hdfs://0\.0\.0\.0:8020/user/training/myinput/purchases\.txt:67108864+67108864" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188155)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113069)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1314137)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(155271168)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108906)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000008" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836199899" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188155)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113069)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1314137)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(155271168)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108906)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000010" TASK_TYPE="MAP" START_TIME="1445836199900" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000009" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000009_0" START_TIME="1445836195582" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000009" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000009_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836202886" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="hdfs://0\.0\.0\.0:8020/user/training/myinput/purchases\.txt:134217728+67108864" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188155)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113069)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1314450)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(155262976)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000009" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836202999" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188155)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(67113069)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(1314450)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(750)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(155262976)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(67108851)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000011" TASK_TYPE="MAP" START_TIME="1445836203000" SPLITS="/default-rack/localhost\.localdomain" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000010" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000010_0" START_TIME="1445836199906" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000010" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000010_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836206461" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=1159/1" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(13748548)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(27685240)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(35179594)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(313258)][(MAP_OUTPUT_RECORDS)(Map output records)(313255)][(MAP_OUTPUT_BYTES)(Map output bytes)(13121353)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(626510)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1450)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(188616704)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(35179391)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000010" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836206701" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(13748548)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(27685240)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(35179594)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(313258)][(MAP_OUTPUT_RECORDS)(Map output records)(313255)][(MAP_OUTPUT_BYTES)(Map output bytes)(13121353)][(SPLIT_RAW_BYTES)(Input split bytes)(109)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(626510)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(1450)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(188616704)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(35179391)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000011" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000011_0" START_TIME="1445836203007" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="MAP" TASKID="task_201510252034_0006_m_000011" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000011_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836206476" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="hdfs://0\.0\.0\.0:8020/user/training/myinput/purchases\.txt:201326592+9986332" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188156)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(9986441)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(195593)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(360)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(152764416)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(9986300)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000011" TASK_TYPE="MAP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836206702" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188156)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(9986441)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(195593)][(MAP_OUTPUT_RECORDS)(Map output records)(0)][(MAP_OUTPUT_BYTES)(Map output bytes)(0)][(SPLIT_RAW_BYTES)(Input split bytes)(108)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(360)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(152764416)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(388177920)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(160763904)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(9986300)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201510252034_0006_r_000000" TASK_ATTEMPT_ID="attempt_201510252034_0006_r_000000_0" START_TIME="1445836161258" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
ReduceAttempt TASK_TYPE="REDUCE" TASKID="task_201510252034_0006_r_000000" TASK_ATTEMPT_ID="attempt_201510252034_0006_r_000000_0" TASK_STATUS="SUCCESS" SHUFFLE_FINISHED="1445836207010" SORT_FINISHED="1445836207511" FINISH_TIME="1445836213759" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="Records R/W\=4477785/1 > reduce" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(198312181)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(198499906)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(3)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42376)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(198312235)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477785)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(1)][(SPILLED_RECORDS)(Spilled Records)(4477785)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7310)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(226029568)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(390443008)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(202768384)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_r_000000" TASK_TYPE="REDUCE" TASK_STATUS="SUCCESS" FINISH_TIME="1445836213797" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(198312181)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(198499906)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(3)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42376)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(198312235)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477785)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(1)][(SPILLED_RECORDS)(Spilled Records)(4477785)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7310)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(226029568)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(390443008)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(202768384)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000012" TASK_TYPE="CLEANUP" START_TIME="1445836213798" SPLITS="" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201510252034_0006_m_000012" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000012_0" START_TIME="1445836213803" TRACKER_NAME="tracker_localhost\.localdomain:localhost\.localdomain/127\.0\.0\.1:35019" HTTP_PORT="50060" .
MapAttempt TASK_TYPE="CLEANUP" TASKID="task_201510252034_0006_m_000012" TASK_ATTEMPT_ID="attempt_201510252034_0006_m_000012_0" TASK_STATUS="SUCCESS" FINISH_TIME="1445836214855" HOSTNAME="/default-rack/localhost\.localdomain" STATE_STRING="cleanup" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188118)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(43311104)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386392064)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Task TASKID="task_201510252034_0006_m_000012" TASK_TYPE="CLEANUP" TASK_STATUS="SUCCESS" FINISH_TIME="1445836215033" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(0)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(188118)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(3)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(SPILLED_RECORDS)(Spilled Records)(0)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(60)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(43311104)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(386392064)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(16252928)]}nullnullnullnullnullnullnullnullnullnullnullnullnull" .
Job JOBID="job_201510252034_0006" FINISH_TIME="1445836215034" JOB_STATUS="SUCCESS" FINISHED_MAPS="12" FINISHED_REDUCES="1" FAILED_MAPS="0" FAILED_REDUCES="0" MAP_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(198312301)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(398882326)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(716296730)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(0)][(HDFS_READ_OPS)(HDFS: Number of read operations)(24)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(8616319)][(MAP_OUTPUT_RECORDS)(Map output records)(4477785)][(MAP_OUTPUT_BYTES)(Map output bytes)(189349014)][(SPLIT_RAW_BYTES)(Input split bytes)(1304)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(SPILLED_RECORDS)(Spilled Records)(8955570)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(30530)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(2173939712)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(4658135040)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(1929166848)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(716254456)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" REDUCE_COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(198312181)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(198499906)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(0)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(3)][(HDFS_READ_OPS)(HDFS: Number of read operations)(2)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42376)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(198312235)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477785)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(1)][(SPILLED_RECORDS)(Spilled Records)(4477785)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(7310)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(226029568)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(390443008)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(202768384)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" COUNTERS="{(org\.apache\.hadoop\.mapreduce\.FileSystemCounter)(File System Counters)[(FILE_BYTES_READ)(FILE: Number of bytes read)(396624482)][(FILE_BYTES_WRITTEN)(FILE: Number of bytes written)(597382232)][(FILE_READ_OPS)(FILE: Number of read operations)(0)][(FILE_LARGE_READ_OPS)(FILE: Number of large read operations)(0)][(FILE_WRITE_OPS)(FILE: Number of write operations)(0)][(HDFS_BYTES_READ)(HDFS: Number of bytes read)(716296730)][(HDFS_BYTES_WRITTEN)(HDFS: Number of bytes written)(3)][(HDFS_READ_OPS)(HDFS: Number of read operations)(26)][(HDFS_LARGE_READ_OPS)(HDFS: Number of large read operations)(0)][(HDFS_WRITE_OPS)(HDFS: Number of write operations)(2)]}{(org\.apache\.hadoop\.mapreduce\.JobCounter)(Job Counters )[(TOTAL_LAUNCHED_MAPS)(Launched map tasks)(12)][(TOTAL_LAUNCHED_REDUCES)(Launched reduce tasks)(1)][(DATA_LOCAL_MAPS)(Data-local map tasks)(12)][(SLOTS_MILLIS_MAPS)(Total time spent by all maps in occupied slots \\(ms\\))(112349)][(SLOTS_MILLIS_REDUCES)(Total time spent by all reduces in occupied slots \\(ms\\))(52501)][(FALLOW_SLOTS_MILLIS_MAPS)(Total time spent by all maps waiting after reserving slots \\(ms\\))(0)][(FALLOW_SLOTS_MILLIS_REDUCES)(Total time spent by all reduces waiting after reserving slots \\(ms\\))(0)]}{(org\.apache\.hadoop\.mapreduce\.TaskCounter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(8616319)][(MAP_OUTPUT_RECORDS)(Map output records)(4477785)][(MAP_OUTPUT_BYTES)(Map output bytes)(189349014)][(SPLIT_RAW_BYTES)(Input split bytes)(1304)][(COMBINE_INPUT_RECORDS)(Combine input records)(0)][(COMBINE_OUTPUT_RECORDS)(Combine output records)(0)][(REDUCE_INPUT_GROUPS)(Reduce input groups)(42376)][(REDUCE_SHUFFLE_BYTES)(Reduce shuffle bytes)(198312235)][(REDUCE_INPUT_RECORDS)(Reduce input records)(4477785)][(REDUCE_OUTPUT_RECORDS)(Reduce output records)(1)][(SPILLED_RECORDS)(Spilled Records)(13433355)][(CPU_MILLISECONDS)(CPU time spent \\(ms\\))(37840)][(PHYSICAL_MEMORY_BYTES)(Physical memory \\(bytes\\) snapshot)(2399969280)][(VIRTUAL_MEMORY_BYTES)(Virtual memory \\(bytes\\) snapshot)(5048578048)][(COMMITTED_HEAP_BYTES)(Total committed heap usage \\(bytes\\))(2131935232)]}{(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)(org\.apache\.hadoop\.mapreduce\.lib\.input\.FileInputFormatCounter)[(BYTES_READ)(BYTES_READ)(716254456)]}nullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnullnull" .
